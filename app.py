from dotenv import load_dotenv

load_dotenv()

import streamlit as st
from langchain_openai import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage


# =========================
# LLM åˆæœŸåŒ–ï¼ˆãƒ¢ãƒ‡ãƒ«åˆ‡ã‚Šæ›¿ãˆå¯ï¼‰
# =========================
llm = ChatOpenAI(
    model="gpt-4o-mini",   # å¿…è¦ã«å¿œã˜ã¦ gpt-5.1 ã‚„ gpt-4o-mini ã«å¤‰æ›´å¯
    temperature=0
)


# =========================
# å°‚é–€å®¶ã”ã¨ã® System ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
# =========================
SYSTEM_PROMPTS = {
    "A": """
ã‚ãªãŸã¯å°‚é–€çš„ãªã€å­è‚²ã¦ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼ã€ã§ã™ã€‚

ãƒ»ä¿è­·è€…ã®ä¸å®‰ã«å¯„ã‚Šæ·»ã†
ãƒ»ç§‘å­¦çš„æ ¹æ‹ ã«åŸºã¥ã„ãŸã‚¢ãƒ‰ãƒã‚¤ã‚¹
ãƒ»å¹´é½¢ã”ã¨ã®ç™ºé”ã«å¿œã˜ãŸææ¡ˆ
ãƒ»è¦ªå­ã®ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä¿ƒã™
ãƒ»è§£æ±ºç­–ã¯ã‚·ãƒ³ãƒ—ãƒ«ã§ã€ã™ãã«å®Ÿè·µå¯èƒ½ãªå½¢ã§æç¤ºã™ã‚‹

è³ªå•è€…ãŒã©ã®å¹´é½¢ã®å­ã‚’æƒ³å®šã—ã¦ã„ã‚‹ã‹ä¸æ˜ãªå ´åˆã¯ã€æœ€åˆã«å¿…è¦ã«å¿œã˜ã¦ç¢ºèªã—ãªãŒã‚‰ä¸å¯§ã«ã‚µãƒãƒ¼ãƒˆã—ã¦ãã ã•ã„ã€‚
""",

    "B": """
ã‚ãªãŸã¯ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªã€æ—…è¡Œãƒ—ãƒ©ãƒ³ãƒŠãƒ¼å…¼ãƒˆãƒ©ãƒ™ãƒ«ã‚³ãƒ³ã‚·ã‚§ãƒ«ã‚¸ãƒ¥ã€ã§ã™ã€‚

ãƒ»æ—…è¡Œå…ˆã®ç‰¹å¾´ã€ãƒ™ã‚¹ãƒˆã‚·ãƒ¼ã‚ºãƒ³ã€å®‰å…¨æ€§ã€è²»ç”¨æ„Ÿã‚’è¸ã¾ãˆã‚‹
ãƒ»ãƒ•ãƒ©ã‚¤ãƒˆã€ãƒ›ãƒ†ãƒ«ã€è¦³å…‰ã‚¹ãƒãƒƒãƒˆã‚’æœ€é©ã«çµ„ã¿åˆã‚ã›ã‚‹
ãƒ»å­é€£ã‚Œæ—…è¡Œãƒ»æ¯å­æ—…è¡Œã«ã‚‚å¯¾å¿œ
ãƒ»æ—…è¡Œåˆå¿ƒè€…ã§ã‚‚å®‰å¿ƒã§ãã‚‹ã‚ˆã†æ˜ç¢ºãªã‚¹ãƒ†ãƒƒãƒ—ã§ææ¡ˆ
ãƒ»å¿…è¦ãªæ³¨æ„ç‚¹ã‚„ä»£æ›¿æ¡ˆã‚‚ç¤ºã™

æ—…è¡Œç›¸è«‡å†…å®¹ã«å¿œã˜ã¦ã€æœ€é©ãªæ—…ç¨‹ã‚„é¸æŠè‚¢ã‚’åˆ†ã‹ã‚Šã‚„ã™ãæç¤ºã—ã¦ãã ã•ã„ã€‚
"""
}


# =========================
# LLMã¸å•ã„åˆã‚ã›ã‚‹é–¢æ•°
# =========================
def ask_llm(user_input: str, expert_type: str) -> str:
    """
    :param user_input: ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›
    :param expert_type: "A" or "B"
    """
    system_content = SYSTEM_PROMPTS.get(expert_type)

    messages = [
        SystemMessage(content=system_content),
        HumanMessage(content=user_input),
    ]

    response = llm.invoke(messages)
    return response.content


# =========================
# Streamlit ã‚¢ãƒ—ãƒª
# =========================
def main():
    st.title("ğŸ“ å°‚é–€å®¶LLMãƒãƒ£ãƒƒãƒˆï¼ˆå­è‚²ã¦ Ã— æ—…è¡Œãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ï¼‰")

    st.markdown(
        """
### ğŸ“ ã‚¢ãƒ—ãƒªã®ä½¿ã„æ–¹

ã“ã®ã‚¢ãƒ—ãƒªã§ã¯ã€  
**ã€Œå­è‚²ã¦ã®å°‚é–€å®¶ã€** ã¾ãŸã¯ **ã€Œæ—…è¡Œãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ã€** ã®ã©ã¡ã‚‰ã‹ã®å½¹å‰²ã§ LLM ãŒå›ç­”ã—ã¾ã™ã€‚

1. ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã§ç›¸è«‡ã—ãŸã„å°‚é–€å®¶ã‚¿ã‚¤ãƒ—ã‚’é¸ã¶  
2. è³ªå•ã‚’å…¥åŠ›ã™ã‚‹  
3. ã€ŒLLMã«è³ªå•ã™ã‚‹ã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™  
4. é¸æŠã—ãŸå°‚é–€å®¶ã¨ã—ã¦ã®å›ç­”ãŒè¿”ã£ã¦ãã¾ã™  

---

"""
    )

    # å°‚é–€å®¶ã‚¿ã‚¤ãƒ—é¸æŠ
    expert_label = st.radio(
        "ç›¸è«‡ã—ãŸã„å°‚é–€å®¶ã‚’é¸ã‚“ã§ãã ã•ã„ï¼š",
        [
            "Aï¼šå­è‚²ã¦ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼ï¼ˆè‚²å…ã®æ‚©ã¿ç›¸è«‡ï¼‰",
            "Bï¼šæ—…è¡Œãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ï¼ˆæ—…ç¨‹ä½œæˆãƒ»æ—…è¡Œç›¸è«‡ï¼‰",
        ]
    )

    # A or B æŠ½å‡º
    expert_type = expert_label[0]  # "A" ã¾ãŸã¯ "B"

    # ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›
    user_input = st.text_area(
        "è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼š",
        height=180,
        placeholder="ä¾‹ï¼‰3æ­³ã®å­ã©ã‚‚ãŒå¤œãªã‹ãªã‹å¯ã¦ãã‚Œã¾ã›ã‚“ã€‚ã©ã†ã—ãŸã‚‰ã„ã„ã§ã™ã‹ï¼Ÿ"
        if expert_type == "A"
        else "ä¾‹ï¼‰4äººå­é€£ã‚Œã§ã‚·ãƒ³ã‚¬ãƒãƒ¼ãƒ«ã«è¡Œãã¾ã™ã€‚ãŠã™ã™ã‚ã®æ—…ç¨‹ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚"
    )

    # ãƒœã‚¿ãƒ³
    if st.button("LLMã«è³ªå•ã™ã‚‹"):
        if not user_input.strip():
            st.warning("è³ªå•å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        else:
            with st.spinner("å›ç­”ã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™â€¦"):
                answer = ask_llm(user_input, expert_type)

            st.markdown("### ğŸ’¡ å›ç­”")
            st.write(answer)


if __name__ == "__main__":
    main()
